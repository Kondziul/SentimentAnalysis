{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T22:02:11.964222900Z",
     "start_time": "2025-02-09T22:01:29.963289100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podstawowe informacje o zbiorze danych:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14050565 entries, 0 to 14050564\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   Date       object\n",
      " 1   text       object\n",
      " 2   Sentiment  object\n",
      "dtypes: object(3)\n",
      "memory usage: 321.6+ MB\n",
      "None\n",
      "\n",
      "Pierwsze 5 wierszy zbioru danych:\n",
      "         Date                                               text Sentiment\n",
      "0  2019-05-27  Cardano: Digitize Currencies; EOS https://t.co...  Positive\n",
      "1  2019-05-27  Another Test tweet that wasn't caught in the s...  Positive\n",
      "2  2019-05-27  Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...  Positive\n",
      "3  2019-05-27  Spiv (Nosar Baz): BITCOIN Is An Asset &amp; NO...  Positive\n",
      "4  2019-05-27  @nwoodfine We have been building on the real #...  Positive\n",
      "\n",
      "Statystyki opisowe zbioru danych:\n",
      "              Date                                               text  \\\n",
      "count     14050565                                           14050565   \n",
      "unique        1901                                           11439638   \n",
      "top     2019-07-11  $EPAZ's Bitcoin Sharing &amp; Blockchain Socia...   \n",
      "freq        549385                                             891106   \n",
      "\n",
      "       Sentiment  \n",
      "count   13159447  \n",
      "unique         3  \n",
      "top     Negative  \n",
      "freq     6659545  \n",
      "\n",
      "Liczba wierszy: 14050565\n",
      "Liczba kolumn: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wczytanie pliku CSV\n",
    "file_path = \"filtered_mbsa_full.csv\"  # Ścieżka do pliku\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Wyświetlenie podstawowych informacji o zbiorze danych\n",
    "print(\"Podstawowe informacje o zbiorze danych:\")\n",
    "print(data.info())  # Informacje o kolumnach, typach danych i brakujących wartościach\n",
    "\n",
    "print(\"\\nPierwsze 5 wierszy zbioru danych:\")\n",
    "print(data.head())  # Podgląd pierwszych 5 wierszy\n",
    "\n",
    "print(\"\\nStatystyki opisowe zbioru danych:\")\n",
    "print(data.describe())  # Podstawowe statystyki opisowe dla danych numerycznych\n",
    "\n",
    "# Wyświetlenie liczby wierszy i kolumn\n",
    "print(f\"\\nLiczba wierszy: {data.shape[0]}\")\n",
    "print(f\"Liczba kolumn: {data.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Usuwanie duplikatów\n",
    "data = data.drop_duplicates()\n",
    "# Usuwanie wierszy z brakującymi wartościami\n",
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T22:02:33.840308100Z",
     "start_time": "2025-02-09T22:02:15.561802600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność analizatora: 55.06%\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Usunięcie neutralnych przykładów\n",
    "filtered_data = data[data[\"Sentiment\"] != \"Neutral\"]\n",
    "\n",
    "# Pobranie pierwszego miliona przykładów\n",
    "filtered_data = filtered_data.head(1000000)\n",
    "\n",
    "# Zapisanie przetworzonego zbioru do nowego pliku CSV\n",
    "filtered_data.to_csv(\"filtered_mbsa_first_million.csv\", index=False)\n",
    "\n",
    "# Inicjalizacja analizatora sentymentu\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Funkcja do klasyfikacji komentarzy\n",
    "def classify_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Przetwarzanie danych i porównanie wyników\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    predicted_sentiment = classify_sentiment(row[\"text\"])\n",
    "    if predicted_sentiment is not None:  # Pomijanie neutralnych wyników\n",
    "        total += 1\n",
    "        if predicted_sentiment == row[\"Sentiment\"]:\n",
    "            correct += 1\n",
    "\n",
    "# Obliczenie dokładności\n",
    "accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "# Wynik\n",
    "print(f\"Dokładność analizatora: {accuracy:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T13:27:41.920250800Z",
     "start_time": "2025-01-14T13:25:56.489184200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz pomyłek (Confusion Matrix):\n",
      "[[1003615 2610275]\n",
      " [ 968795 2531500]]\n",
      "Accuracy:  49.69%\n",
      "Precision: 49.23%\n",
      "Recall:    72.32%\n",
      "F1-score:  58.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# (1) Przykładowe wczytanie / przefiltrowanie danych\n",
    "# ---------------------------------------------------\n",
    "filtered_data = data[data[\"Sentiment\"] != \"Neutral\"]\n",
    "\n",
    "\n",
    "# (2) Inicjalizacja analizatora sentymentu\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# (3) Funkcja do klasyfikacji komentarzy\n",
    "def classify_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# (4) Listy do przechowywania etykiet rzeczywistych i przewidywanych\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# (5) Klasyfikacja i gromadzenie danych do obliczania metryk\n",
    "for index, row in filtered_data.iterrows():\n",
    "    predicted_sentiment = classify_sentiment(row[\"text\"])\n",
    "    # Ignorujemy przypadki, gdy model zwraca None (neutralne)\n",
    "    if predicted_sentiment is not None:\n",
    "        y_true.append(row[\"Sentiment\"])\n",
    "        y_pred.append(predicted_sentiment)\n",
    "\n",
    "# (6) Obliczanie macierzy pomyłek oraz metryk\n",
    "# ------------------------------------------\n",
    "# labels określa kolejność etykiet w macierzy [Negative, Positive]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[\"Negative\", \"Positive\"])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "recall = recall_score(y_true, y_pred, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "f1 = f1_score(y_true, y_pred, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "\n",
    "# (7) Wyświetlenie wyników\n",
    "print(\"Macierz pomyłek (Confusion Matrix):\")\n",
    "print(cm)\n",
    "print(f\"Accuracy:  {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall:    {recall:.2%}\")\n",
    "print(f\"F1-score:  {f1:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T22:23:10.402185700Z",
     "start_time": "2025-02-09T22:02:53.272066400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unikalne w y_true: {nan, 'Negative', 'Positive'}\n",
      "Unikalne w y_pred: {'Negative', 'Positive'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Unikalne w y_true:\", set(y_true))\n",
    "print(\"Unikalne w y_pred:\", set(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T21:58:24.336568200Z",
     "start_time": "2025-02-09T21:58:24.228676100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
