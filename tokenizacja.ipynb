{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T20:12:51.084783500Z",
     "start_time": "2025-01-06T20:12:33.307541400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wczytanie danych\n",
    "file_path = \"filtered_mbsa_full_clearedBERT_onlycleanedtext.csv\"  # Zmień nazwę pliku na odpowiednią\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Zamiana NaN na pusty ciąg znaków\n",
    "data['text'] = data['text'].fillna('')\n",
    "\n",
    "# Upewnienie się, że wszystkie wartości w kolumnie 'text' są typu string\n",
    "data['text'] = data['text'].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T20:12:55.506347400Z",
     "start_time": "2025-01-06T20:12:53.000343300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizowanie zbioru treningowego...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizacja:  93%|█████████▎| 8972085/9608460 [1:31:00<07:32, 1406.50text/s]  "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Mapowanie etykiet na liczby\n",
    "label_mapping = {\"Negative\": 0, \"Positive\": 1, \"Neutral\": 2}\n",
    "data['label'] = data['Sentiment'].map(label_mapping)\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['text'].tolist(),\n",
    "    data['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=data['label']\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Funkcja tokenizująca z paskiem postępu\n",
    "def tokenize_with_progress(texts, tokenizer, max_length=256):\n",
    "    tokenized_data = []\n",
    "    for text in tqdm(texts, desc=\"Tokenizacja\", unit=\"text\"):\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_data.append({key: val.squeeze(0).tolist() for key, val in tokenized.items()})\n",
    "    return tokenized_data\n",
    "\n",
    "# Tokenizacja danych\n",
    "print(\"Tokenizowanie zbioru treningowego...\")\n",
    "train_encodings = tokenize_with_progress(train_texts, tokenizer)\n",
    "\n",
    "print(\"Tokenizowanie zbioru walidacyjnego...\")\n",
    "val_encodings = tokenize_with_progress(val_texts, tokenizer)\n",
    "\n",
    "# Zapisanie ztokenizowanych danych do plików\n",
    "with open(\"train_tokenized.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_encodings, f)\n",
    "\n",
    "with open(\"val_tokenized.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_encodings, f)\n",
    "\n",
    "print(\"Ztokenizowane dane zapisano do plików: train_tokenized.pkl i val_tokenized.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-01-06T20:13:14.915321400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
